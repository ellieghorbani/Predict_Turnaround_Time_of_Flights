{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /home/elaheh/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/elaheh/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/elaheh/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /home/elaheh/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/elaheh/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/elaheh/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/elaheh/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/elaheh/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, date, time \n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data: (554285, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>airport_A</th>\n",
       "      <th>airport_B</th>\n",
       "      <th>airport_C</th>\n",
       "      <th>turnaround_time_ B</th>\n",
       "      <th>DEPARTURE_DELAY_AB</th>\n",
       "      <th>ARRIVAL_DELAY_AB</th>\n",
       "      <th>ELAPSED_TIME_AB</th>\n",
       "      <th>...</th>\n",
       "      <th>DEPARTURE_day_AB</th>\n",
       "      <th>DEPARTURE_month_AB</th>\n",
       "      <th>ARRIVAL_HOUR_AB</th>\n",
       "      <th>ARRIVAL_weekday_AB</th>\n",
       "      <th>ARRIVAL_day_AB</th>\n",
       "      <th>ARRIVAL_month_AB</th>\n",
       "      <th>SCHEDULED_DEPARTURE_HOUR_BC</th>\n",
       "      <th>SCHEDULED_DEPARTURE_weekday_BC</th>\n",
       "      <th>SCHEDULED_DEPARTURE_day_BC</th>\n",
       "      <th>SCHEDULED_DEPARTURE_month_BC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>21901</td>\n",
       "      <td>OO</td>\n",
       "      <td>SLC</td>\n",
       "      <td>ORD</td>\n",
       "      <td>SLC</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>21902</td>\n",
       "      <td>OO</td>\n",
       "      <td>ORD</td>\n",
       "      <td>SLC</td>\n",
       "      <td>ORD</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>21903</td>\n",
       "      <td>OO</td>\n",
       "      <td>SLC</td>\n",
       "      <td>ORD</td>\n",
       "      <td>MSP</td>\n",
       "      <td>10.983333</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>21904</td>\n",
       "      <td>OO</td>\n",
       "      <td>ORD</td>\n",
       "      <td>MSP</td>\n",
       "      <td>ORD</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>36.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1 AIRLINE airport_A airport_B airport_C  \\\n",
       "0           0         21901      OO       SLC       ORD       SLC   \n",
       "1           1         21902      OO       ORD       SLC       ORD   \n",
       "2           2         21903      OO       SLC       ORD       MSP   \n",
       "3           3         21904      OO       ORD       MSP       ORD   \n",
       "\n",
       "   turnaround_time_ B  DEPARTURE_DELAY_AB  ARRIVAL_DELAY_AB  ELAPSED_TIME_AB  \\\n",
       "0            0.783333                 6.0              25.0            218.0   \n",
       "1            0.550000                32.0              18.0            209.0   \n",
       "2           10.983333                11.0              11.0            191.0   \n",
       "3            0.466667                36.0              30.0             89.0   \n",
       "\n",
       "   ...  DEPARTURE_day_AB  DEPARTURE_month_AB  ARRIVAL_HOUR_AB  \\\n",
       "0  ...                 1                   1               12   \n",
       "1  ...                 1                   1               15   \n",
       "2  ...                 1                   1               20   \n",
       "3  ...                 2                   1                9   \n",
       "\n",
       "   ARRIVAL_weekday_AB  ARRIVAL_day_AB  ARRIVAL_month_AB  \\\n",
       "0                   3               1                 1   \n",
       "1                   3               1                 1   \n",
       "2                   3               1                 1   \n",
       "3                   4               2                 1   \n",
       "\n",
       "   SCHEDULED_DEPARTURE_HOUR_BC  SCHEDULED_DEPARTURE_weekday_BC  \\\n",
       "0                           12                               3   \n",
       "1                           16                               3   \n",
       "2                            7                               4   \n",
       "3                            9                               4   \n",
       "\n",
       "   SCHEDULED_DEPARTURE_day_BC  SCHEDULED_DEPARTURE_month_BC  \n",
       "0                           1                             1  \n",
       "1                           1                             1  \n",
       "2                           2                             1  \n",
       "3                           2                             1  \n",
       "\n",
       "[4 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data_seen_OO_airlines.csv\")\n",
    "print('shape of data:', data.shape)\n",
    "data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'AIRLINE', 'airport_A', 'airport_B',\n",
       "       'airport_C', 'turnaround_time_ B', 'DEPARTURE_DELAY_AB',\n",
       "       'ARRIVAL_DELAY_AB', 'ELAPSED_TIME_AB', 'DISTANCE_AB', 'DISTANCEBC',\n",
       "       'DEPARTURE_HOUR_AB', 'DEPARTURE_weekday_AB', 'DEPARTURE_day_AB',\n",
       "       'DEPARTURE_month_AB', 'ARRIVAL_HOUR_AB', 'ARRIVAL_weekday_AB',\n",
       "       'ARRIVAL_day_AB', 'ARRIVAL_month_AB', 'SCHEDULED_DEPARTURE_HOUR_BC',\n",
       "       'SCHEDULED_DEPARTURE_weekday_BC', 'SCHEDULED_DEPARTURE_day_BC',\n",
       "       'SCHEDULED_DEPARTURE_month_BC'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data['turnaround_time_ B']\n",
    "features = pd.get_dummies(data[['airport_A', 'airport_B', 'airport_C',\n",
    "       'DEPARTURE_DELAY_AB', 'ARRIVAL_DELAY_AB',\n",
    "       'ELAPSED_TIME_AB', 'DISTANCE_AB', 'DISTANCEBC', 'DEPARTURE_HOUR_AB',\n",
    "       'DEPARTURE_weekday_AB', 'DEPARTURE_day_AB', 'DEPARTURE_month_AB',\n",
    "       'ARRIVAL_HOUR_AB', 'ARRIVAL_weekday_AB', 'ARRIVAL_day_AB',\n",
    "       'ARRIVAL_month_AB', 'SCHEDULED_DEPARTURE_HOUR_BC',\n",
    "       'SCHEDULED_DEPARTURE_weekday_BC', 'SCHEDULED_DEPARTURE_day_BC',\n",
    "       'SCHEDULED_DEPARTURE_month_BC']])\n",
    "\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target.copy()\n",
    "target[target <= 4]= 1\n",
    "target[target  > 4]= 2\n",
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models:\n",
    "- Logistic Regression\n",
    "- k-Nearest Neighbors\n",
    "- Decision Trees\n",
    "- Support Vector Machine\n",
    "- Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def logistic_model(features_data, target_data, rand_state):\n",
    "    \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_data, target_data, \n",
    "                                                        random_state=rand_state, test_size=0.2)\n",
    "\n",
    "    model = LogisticRegression(solver='liblinear', random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_test_predict = model.predict(X_test)\n",
    "    #-------------------------------------------------------\n",
    "    cm1 = confusion_matrix(y_test, y_test_predict)\n",
    "    fig, ax = plt.subplots(figsize=(5, 4))\n",
    "    \n",
    "    ax.imshow(cm1)\n",
    "    ax.grid(False)\n",
    "    ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "    ax.set_ylim(1.5, -0.5)\n",
    "    ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "    plt.sca(ax)\n",
    "    #plt.title('Predict Test Data')\n",
    "        \n",
    "    print(cm1.sum(axis=0)[0])\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax.text(j, i, ('% {}').format(int(cm1[i, j]/cm1.sum(axis= 1)[i]*100)), ha='center', va='center', color='red')\n",
    "    #plt.show()\n",
    "    plt.savefig('confusion_matrix_OO_LogisticRegression.png')\n",
    "    print(\"Precision_0 ={:.2f}\".format((cm1[0,0]/(cm1[0,0] + cm1[1,0]))))\n",
    "    print(\"Recall_0 =%f\" %(cm1[0,0]/(cm1[0,0]+cm1[0,1])))\n",
    "    print(\"Precision_1 ={:.2f}\".format((cm1[1,1]/(cm1[1,1] + cm1[0,1]))))\n",
    "    print(\"Recall_1 =%f\" %(cm1[1,1]/(cm1[1,1]+cm1[1,0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model(features, target, 1222)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def knn_model(features_data, target_data, rand_state, number_neighbors):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_data, target_data, \n",
    "                                                        random_state=rand_state, test_size=0.2)\n",
    "    error_rates = []\n",
    "    for i in range(1,number_neighbors):\n",
    "        model = KNeighborsClassifier(n_neighbors = i)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_test_predict = model.predict(X_test)\n",
    "        error_rates.append(np.mean(y_test_predict != y_test))\n",
    "    #-------------------------------------------------------\n",
    "    min_error = min(error_rates)\n",
    "    max_knn = min(np.where(error_rates == min_error))\n",
    "    plt.plot(error_rates)\n",
    "    plt.xlabel('Number_neighbors')\n",
    "    plt.ylabel('error_rates')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print('max_knn = ',max_knn[0])\n",
    "    #-----------------------------------------------------------\n",
    "    model = KNeighborsClassifier(n_neighbors = 7)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_test_predict = model.predict(X_test)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_test_predict = model.predict(X_test)\n",
    "    #-------------------------------------------------------\n",
    "    cm1 = confusion_matrix(y_test, y_test_predict)\n",
    "    fig, ax = plt.subplots(figsize=(4, 4))\n",
    "    \n",
    "    ax.imshow(cm1)\n",
    "    ax.grid(False)\n",
    "    ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "    ax.set_ylim(1.5, -0.5)\n",
    "    ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "    plt.sca(ax)\n",
    "    #plt.title('Predict Test Data')\n",
    "        \n",
    "    print(cm1.sum(axis=0)[0])\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax.text(j, i, ('% {}').format(int(cm1[i, j]/cm1.sum(axis= 1)[i]*100)), ha='center', va='center', color='red')\n",
    "    plt.show()\n",
    "    plt.savefig('confusion_matrix_OO_KNeighborsClassifier.png')\n",
    "    print(\"Precision_0 ={:.2f}\".format((cm1[0,0]/(cm1[0,0] + cm1[1,0]))))\n",
    "    print(\"Recall_0 =%f\" %(cm1[0,0]/(cm1[0,0]+cm1[0,1])))\n",
    "    print(\"Precision_1 ={:.2f}\".format((cm1[1,1]/(cm1[1,1] + cm1[0,1]))))\n",
    "    print(\"Recall_1 =%f\" %(cm1[1,1]/(cm1[1,1]+cm1[1,0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model(features, target,1014, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def RandomForestClassifier_model(features_data, target_data, rand_state):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_data, target_data, \n",
    "                                                        random_state=rand_state, test_size=0.2)\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators= 200, max_depth = 30, random_state=100)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_test_predict = model.predict(X_test)\n",
    "    #-------------------------------------------------------\n",
    "    cm1 = confusion_matrix(y_test, y_test_predict)\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    \n",
    "    ax.imshow(cm1)\n",
    "    ax.grid(False)\n",
    "    ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "    ax.set_ylim(1.5, -0.5)\n",
    "    ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "    plt.sca(ax)\n",
    "    #plt.title('Predict Test Data')\n",
    "        \n",
    "    print(cm1.sum(axis=0)[0])\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax.text(j, i, ('% {}').format(int(cm1[i, j]/cm1.sum(axis= 1)[i]*100)), ha='center', va='center', color='red')\n",
    "    #plt.show()\n",
    "    plt.savefig('confusion_matrix_OO_RandomForestClassifier.png')\n",
    "    print(\"Precision_0 ={:.2f}\".format((cm1[0,0]/(cm1[0,0] + cm1[1,0]))))\n",
    "    print(\"Recall_0 =%f\" %(cm1[0,0]/(cm1[0,0]+cm1[0,1])))\n",
    "    print(\"Precision_1 ={:.2f}\".format((cm1[1,1]/(cm1[1,1] + cm1[0,1]))))\n",
    "    print(\"Recall_1 =%f\" %(cm1[1,1]/(cm1[1,1]+cm1[1,0])))\n",
    "    \n",
    "    all_features = model.feature_importances_\n",
    "    feat_scores_gbr = pd.DataFrame({'Fraction of Samples Affected {} {}'.format('Random Forest Classifier', 'target') : all_features}, index=X_train.columns)\n",
    "    feat_scores_gbr = feat_scores_gbr.sort_values(by='Fraction of Samples Affected target') \n",
    "    feat_scores_gbr = feat_scores_gbr[-15:]\n",
    "    plt.figure(figsize=(10, 50))\n",
    "    feat_scores_gbr.plot(kind='barh')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(\"the_most_important_OO_RandomForestClassifier.png\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RandomForestClassifier = RandomForestClassifier_model(features, target, 1040)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "def SupportVectorMachine_model(features_data, target_data, num_sample, rand_state):\n",
    "    features_data_sub = features_data.sample(num_sample)\n",
    "    features_unseen =  features_data.drop(features_data_sub.index)\n",
    "    target_data_sub = target_data[features_data_sub.index]\n",
    "    target_unseen = target_data.drop(features_data_sub.index)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_data_sub, target_data_sub, \n",
    "                                                        random_state=rand_state, test_size=0.2)\n",
    "\n",
    "    model = SVC(kernel='linear')\n",
    "    model.fit(X_train, y_train)\n",
    "    y_test_predict = model.predict(X_test)\n",
    "    y_predict = model.predict(features_unseen)\n",
    "    #-------------------------------------------------------\n",
    "    cm1 = confusion_matrix(y_test, y_test_predict)\n",
    "    cm2 = confusion_matrix(target_unseen, y_predict)\n",
    "    fig, ax = plt.subplots(1,2, figsize=(8, 8))\n",
    "    for k in range(2):\n",
    "        ax[k].imshow(cm1)\n",
    "        ax[k].grid(False)\n",
    "        ax[k].xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "        ax[k].set_ylim(1.5, -0.5)\n",
    "    ax[0].yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "    plt.sca(ax[0])\n",
    "    plt.title('Predict Test Data')\n",
    "    plt.sca(ax[1])\n",
    "    plt.title('Predict Unseen Data')\n",
    "    \n",
    "    print(cm1.sum(axis=0)[0])\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax[0].text(j, i, ('% {}').format(int(cm1[i, j]/cm1.sum(axis= 1)[i]*100)), ha='center', va='center', color='red')\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax[1].text(j, i, ('% {}').format(int(cm2[i, j]/cm2.sum(axis= 1)[i]*100)), ha='center', va='center', color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SupportVectorMachine_model(features, target, 400000, 1059)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def GaussianNaiveBayes_model(features_data, target_data, rand_state):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_data, target_data, \n",
    "                                                        random_state=rand_state, test_size=0.2)\n",
    "\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_test_predict = model.predict(X_test)\n",
    "    #-------------------------------------------------------\n",
    "    cm1 = confusion_matrix(y_test, y_test_predict)\n",
    "    fig, ax = plt.subplots(figsize=(4, 4))\n",
    "    \n",
    "    ax.imshow(cm1)\n",
    "    ax.grid(False)\n",
    "    ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "    ax.set_ylim(1.5, -0.5)\n",
    "    ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "    plt.sca(ax)\n",
    "    #plt.title('Predict Test Data')\n",
    "        \n",
    "    print(cm1.sum(axis=0)[0])\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax.text(j, i, ('% {}').format(int(cm1[i, j]/cm1.sum(axis= 1)[i]*100)), ha='center', va='center', color='red')\n",
    "    plt.show()\n",
    "    plt.savefig('confusion_matrix_OO_GaussianNaiveBayes.png')\n",
    "    print(\"Precision_0 ={:.2f}\".format((cm1[0,0]/(cm1[0,0] + cm1[1,0]))))\n",
    "    print(\"Recall_0 =%f\" %(cm1[0,0]/(cm1[0,0]+cm1[0,1])))\n",
    "    print(\"Precision_1 ={:.2f}\".format((cm1[1,1]/(cm1[1,1] + cm1[0,1]))))\n",
    "    print(\"Recall_1 =%f\" %(cm1[1,1]/(cm1[1,1]+cm1[1,0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GaussianNaiveBayes_model(features, target, 1235)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
