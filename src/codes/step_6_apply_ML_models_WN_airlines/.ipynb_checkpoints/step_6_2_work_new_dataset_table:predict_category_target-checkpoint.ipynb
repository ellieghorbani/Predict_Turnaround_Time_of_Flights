{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, date, time \n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data_seen_WN_airlines.csv\")\n",
    "print('shape of data:', data.shape)\n",
    "data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data['turnaround_time_ B']\n",
    "features = pd.get_dummies(data[['airport_A', 'airport_B', 'airport_C',\n",
    "       'DEPARTURE_DELAY_AB', 'ARRIVAL_DELAY_AB',\n",
    "       'ELAPSED_TIME_AB', 'DISTANCE_AB', 'DISTANCEBC', 'DEPARTURE_HOUR_AB',\n",
    "       'DEPARTURE_weekday_AB', 'DEPARTURE_day_AB', 'DEPARTURE_month_AB',\n",
    "       'ARRIVAL_HOUR_AB', 'ARRIVAL_weekday_AB', 'ARRIVAL_day_AB',\n",
    "       'ARRIVAL_month_AB', 'SCHEDULED_DEPARTURE_HOUR_BC',\n",
    "       'SCHEDULED_DEPARTURE_weekday_BC', 'SCHEDULED_DEPARTURE_day_BC',\n",
    "       'SCHEDULED_DEPARTURE_month_BC']])\n",
    "\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target.copy()\n",
    "target[target <= 4]= 1\n",
    "target[target  > 4]= 2\n",
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models:\n",
    "- Logistic Regression\n",
    "- k-Nearest Neighbors\n",
    "- Decision Trees\n",
    "- Support Vector Machine\n",
    "- Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def logistic_model(features_data, target_data, rand_state):\n",
    "    \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_data, target_data, \n",
    "                                                        random_state=rand_state, test_size=0.2)\n",
    "\n",
    "    model = LogisticRegression(solver='liblinear', random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_test_predict = model.predict(X_test)\n",
    "    #-------------------------------------------------------\n",
    "    cm1 = confusion_matrix(y_test, y_test_predict)\n",
    "    fig, ax = plt.subplots(figsize=(5, 4))\n",
    "    \n",
    "    ax.imshow(cm1)\n",
    "    ax.grid(False)\n",
    "    ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "    ax.set_ylim(1.5, -0.5)\n",
    "    ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "    plt.sca(ax)\n",
    "    #plt.title('Predict Test Data')\n",
    "       \n",
    "    print(cm1.sum(axis=0)[0])\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax.text(j, i, ('% {}').format(int(cm1[i, j]/cm1.sum(axis= 1)[i]*100)), ha='center', va='center', color='red')\n",
    "    #plt.show()\n",
    "    plt.savefig('confusion_matrix_WN_LogisticRegression.png')\n",
    "    print(\"Precision_0 ={:.2f}\".format((cm1[0,0]/(cm1[0,0] + cm1[1,0]))))\n",
    "    print(\"Recall_0 =%f\" %(cm1[0,0]/(cm1[0,0]+cm1[0,1])))\n",
    "    print(\"Precision_1 ={:.2f}\".format((cm1[1,1]/(cm1[1,1] + cm1[0,1]))))\n",
    "    print(\"Recall_1 =%f\" %(cm1[1,1]/(cm1[1,1]+cm1[1,0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model(features, target, 1222)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def knn_model(features_data, target_data, rand_state, number_neighbors):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_data, target_data, \n",
    "                                                        random_state=rand_state, test_size=0.2)\n",
    "    error_rates = []\n",
    "    for i in range(1,number_neighbors):\n",
    "        print(i)\n",
    "        model = KNeighborsClassifier(n_neighbors = i)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_test_predict = model.predict(X_test)\n",
    "        error_rates.append(np.mean(y_test_predict != y_test))\n",
    "    #-------------------------------------------------------\n",
    "    min_error = min(error_rates)\n",
    "    max_knn = min(np.where(error_rates == min_error))\n",
    "    plt.plot(error_rates)\n",
    "    plt.xlabel('Number_neighbors')\n",
    "    plt.ylabel('error_rates')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print('max_knn = ',max_knn[0])\n",
    "    \n",
    "    \n",
    "def knn_with_best_k(features_data, target_data, rand_state, number_neighbors):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(features_data, target_data, \n",
    "                                                        random_state=rand_state, test_size=0.2)\n",
    "        #-----------------------------------------------------------\n",
    "        model = KNeighborsClassifier(n_neighbors = number_neighbors)\n",
    "        print(\"1\")\n",
    "        model.fit(X_train, y_train)\n",
    "        print(\"2\")\n",
    "        y_test_predict = model.predict(X_test)\n",
    "        print(\"3\")\n",
    "        #-------------------------------------------------------\n",
    "        cm1 = confusion_matrix(y_test, y_test_predict)\n",
    "        fig, ax = plt.subplots(figsize=(4, 4))\n",
    "    \n",
    "        ax.imshow(cm1)\n",
    "        ax.grid(False)\n",
    "        ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "        ax.set_ylim(1.5, -0.5)\n",
    "        ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "        plt.sca(ax)\n",
    "        # plt.title('Predict Test Data')\n",
    "        \n",
    "        print(cm1.sum(axis=0)[0])\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                ax.text(j, i, ('% {}').format(int(cm1[i, j]/cm1.sum(axis= 1)[i]*100)), ha='center', va='center', color='red')\n",
    "        plt.show()\n",
    "        plt.savefig('confusion_matrix_WN_KNeighborsClassifier.png')\n",
    "        print(\"Precision_0 ={:.2f}\".format((cm1[0,0]/(cm1[0,0] + cm1[1,0]))))\n",
    "        print(\"Recall_0 =%f\" %(cm1[0,0]/(cm1[0,0]+cm1[0,1])))\n",
    "        print(\"Precision_1 ={:.2f}\".format((cm1[1,1]/(cm1[1,1] + cm1[0,1]))))\n",
    "        print(\"Recall_1 =%f\" %(cm1[1,1]/(cm1[1,1]+cm1[1,0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model(features, target,1014, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_with_best_k(features, target,1014,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def RandomForestClassifier_model(features_data, target_data, rand_state):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_data, target_data, \n",
    "                                                        random_state=rand_state, test_size=0.2)\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators= 200, max_depth = 30, random_state=100)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_test_predict = model.predict(X_test)\n",
    "    #-------------------------------------------------------\n",
    "    cm1 = confusion_matrix(y_test, y_test_predict)\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    \n",
    "    ax.imshow(cm1)\n",
    "    ax.grid(False)\n",
    "    ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "    ax.set_ylim(1.5, -0.5)\n",
    "    ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "    plt.sca(ax)\n",
    "    #plt.title('Predict Test Data')\n",
    "        \n",
    "    print(cm1.sum(axis=0)[0])\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax.text(j, i, ('% {}').format(int(cm1[i, j]/cm1.sum(axis= 1)[i]*100)), ha='center', va='center', color='red')\n",
    "    #plt.show()\n",
    "    plt.savefig('confusion_matrix_WN_RandomForestClassifier.png')\n",
    "    print(\"Precision_0 ={:.2f}\".format((cm1[0,0]/(cm1[0,0] + cm1[1,0]))))\n",
    "    print(\"Recall_0 =%f\" %(cm1[0,0]/(cm1[0,0]+cm1[0,1])))\n",
    "    print(\"Precision_1 ={:.2f}\".format((cm1[1,1]/(cm1[1,1] + cm1[0,1]))))\n",
    "    print(\"Recall_1 =%f\" %(cm1[1,1]/(cm1[1,1]+cm1[1,0])))\n",
    "    \n",
    "    all_features = model.feature_importances_\n",
    "    feat_scores_model = pd.DataFrame({'Fraction of Features': all_features}, index=X_train.columns)\n",
    "    feat_scores_model = feat_scores_model.sort_values(by='Fraction of Features')\n",
    "    feat_scores_model = feat_scores_model[-15:]\n",
    "    print(feat_scores_model)\n",
    "    plt.figure(figsize=(50, 50))\n",
    "    feat_scores_model.plot(kind='barh')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(\"the_most_important_WN_RandomForestClassifier.png\", bbox_inches='tight')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RandomForestClassifier = RandomForestClassifier_model(features, target, 1259)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def GaussianNaiveBayes_model(features_data, target_data, rand_state):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_data, target_data, \n",
    "                                                        random_state=rand_state, test_size=0.2)\n",
    "\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_test_predict = model.predict(X_test)\n",
    "    #-------------------------------------------------------\n",
    "    cm1 = confusion_matrix(y_test, y_test_predict)\n",
    "    fig, ax = plt.subplots(figsize=(4, 4))\n",
    "    \n",
    "    ax.imshow(cm1)\n",
    "    ax.grid(False)\n",
    "    ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "    ax.set_ylim(1.5, -0.5)\n",
    "    ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "    plt.sca(ax)\n",
    "    #plt.title('Predict Test Data')\n",
    "        \n",
    "    print(cm1.sum(axis=0)[0])\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax.text(j, i, ('% {}').format(int(cm1[i, j]/cm1.sum(axis= 1)[i]*100)), ha='center', va='center', color='red')\n",
    "    plt.show()\n",
    "    plt.savefig('confusion_matrix_WN_GaussianNaiveBayes.png')\n",
    "    print(\"Precision_0 ={:.2f}\".format((cm1[0,0]/(cm1[0,0] + cm1[1,0]))))\n",
    "    print(\"Recall_0 =%f\" %(cm1[0,0]/(cm1[0,0]+cm1[0,1])))\n",
    "    print(\"Precision_1 ={:.2f}\".format((cm1[1,1]/(cm1[1,1] + cm1[0,1]))))\n",
    "    print(\"Recall_1 =%f\" %(cm1[1,1]/(cm1[1,1]+cm1[1,0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GaussianNaiveBayes_model(features, target, 1235)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
