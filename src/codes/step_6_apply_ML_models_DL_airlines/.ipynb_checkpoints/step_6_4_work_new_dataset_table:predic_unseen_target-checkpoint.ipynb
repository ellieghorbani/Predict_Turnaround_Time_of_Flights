{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, date, time \n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def RandomForestClassifier_model(features_data, target_data, rand_state):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_data, target_data, \n",
    "                                                        random_state=rand_state, test_size=0.2)\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators= 200, max_depth = 30, random_state=100)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_test_predict = model.predict(X_test)\n",
    "    #-------------------------------------------------------\n",
    "    cm1 = confusion_matrix(y_test, y_test_predict)\n",
    "    fig, ax = plt.subplots(figsize=(4, 4))\n",
    "    \n",
    "    ax.imshow(cm1)\n",
    "    ax.grid(False)\n",
    "    ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "    ax.set_ylim(1.5, -0.5)\n",
    "    ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "    plt.sca(ax)\n",
    "    #plt.title('Predict Test Data')\n",
    "        \n",
    "    print(cm1.sum(axis=0)[0])\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax.text(j, i, ('% {}').format(int(cm1[i, j]/cm1.sum(axis= 1)[i]*100)), ha='center', va='center', color='red')\n",
    "    plt.show()\n",
    "    plt.savefig('confusion_matrix_AA_RandomForestClassifier.png')\n",
    "    print(\"Precision_0 ={:.2f}\".format((cm1[0,0]/(cm1[0,0] + cm1[1,0]))))\n",
    "    print(\"Recall_0 =%f\" %(cm1[0,0]/(cm1[0,0]+cm1[0,1])))\n",
    "    print(\"Precision_1 ={:.2f}\".format((cm1[1,1]/(cm1[1,1] + cm1[0,1]))))\n",
    "    print(\"Recall_1 =%f\" %(cm1[1,1]/(cm1[1,1]+cm1[1,0])))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def gbr_model(features_data, target_data, num_sample, rand_state, name_target):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_data, target_data,\n",
    "                                                    random_state=rand_state, test_size=0.2)\n",
    "    gbr = GradientBoostingRegressor(n_estimators = 500, max_depth = 10, min_samples_split = 5,\n",
    "          learning_rate = 0.1, loss= 'ls')\n",
    "    gbr.fit(X_train, y_train)\n",
    "    y_test_predict = gbr.predict(X_test)\n",
    "    \n",
    "    data_frame = pd.DataFrame([[name_target, 'Gradient Boosting Regressor', np.sqrt(sum((y_test - y_test_predict)**2)/len(y_test)),\n",
    "                              np.sqrt(sum((y_test - np.mean(y_test))**2)/len(y_test)),\n",
    "                              np.mean(target_data),np.mean(target_data), np.mean(y_train), \n",
    "                              np.mean(y_test), np.mean(y_test_predict)]], \n",
    "                              columns = ['name_target','model','RMS_test_predict','RMS_test_mean',\n",
    "                                        'mean_target','mean_sample', 'mean_train', \n",
    "                                        'mean_test', 'mean_test_predict'])\n",
    "    # Plot the feature importance\n",
    "    \n",
    "    all_features = gbr.feature_importances_\n",
    "    feat_scores_gbr = pd.DataFrame({'Fraction of Samples Affected {} {}'.format('Gradient Boosting', name_target) : all_features}, index=X_train.columns)\n",
    "    feat_scores_gbr = feat_scores_gbr.sort_values(by='Fraction of Samples Affected {} {}'.format('Gradient Boosting', name_target) )\n",
    "    feat_scores_gbr = feat_scores_gbr[-15:]\n",
    "    plt.figure(figsize=(10, 50))\n",
    "    feat_scores_gbr.plot(kind='barh')\n",
    "    plt.legend(loc='lower right')\n",
    "    \n",
    "    return y_test, y_test_predict, data_frame, feat_scores_gbr, gbr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_seen = pd.read_csv(\"data_seen_DL_airlines.csv\")\n",
    "data_unseen = pd.read_csv(\"data_unseen_DL_airlines.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_seen = data_seen['turnaround_time_ B']\n",
    "features_seen = pd.get_dummies(data_seen[['airport_A', 'airport_B', 'airport_C',\n",
    "       'DEPARTURE_DELAY_AB', 'ARRIVAL_DELAY_AB',\n",
    "       'ELAPSED_TIME_AB', 'DISTANCE_AB', 'DISTANCEBC', 'DEPARTURE_HOUR_AB',\n",
    "       'DEPARTURE_weekday_AB', 'DEPARTURE_day_AB', 'DEPARTURE_month_AB',\n",
    "       'ARRIVAL_HOUR_AB', 'ARRIVAL_weekday_AB', 'ARRIVAL_day_AB',\n",
    "       'ARRIVAL_month_AB', 'SCHEDULED_DEPARTURE_HOUR_BC',\n",
    "       'SCHEDULED_DEPARTURE_weekday_BC', 'SCHEDULED_DEPARTURE_day_BC',\n",
    "       'SCHEDULED_DEPARTURE_month_BC']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_unseen = data_unseen['turnaround_time_ B']\n",
    "features_unseen = pd.get_dummies(data_unseen[['airport_A', 'airport_B', 'airport_C',\n",
    "       'DEPARTURE_DELAY_AB', 'ARRIVAL_DELAY_AB',\n",
    "       'ELAPSED_TIME_AB', 'DISTANCE_AB', 'DISTANCEBC', 'DEPARTURE_HOUR_AB',\n",
    "       'DEPARTURE_weekday_AB', 'DEPARTURE_day_AB', 'DEPARTURE_month_AB',\n",
    "       'ARRIVAL_HOUR_AB', 'ARRIVAL_weekday_AB', 'ARRIVAL_day_AB',\n",
    "       'ARRIVAL_month_AB', 'SCHEDULED_DEPARTURE_HOUR_BC',\n",
    "       'SCHEDULED_DEPARTURE_weekday_BC', 'SCHEDULED_DEPARTURE_day_BC',\n",
    "       'SCHEDULED_DEPARTURE_month_BC']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Diffirence number of seen and unseen features:',features_seen.shape[1]-features_unseen.shape[1])\n",
    "for i in features_seen:\n",
    "    if i not in features_unseen:\n",
    "        features_unseen[i]= 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make model from seen data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_seen_bio = target_seen.copy()\n",
    "target_seen_bio[target_seen <= 4]= 1\n",
    "target_seen_bio[target_seen  > 4]= 2\n",
    "target_seen_bio.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_model = RandomForestClassifier_model(features_seen, target_seen_bio, 1040)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_1, target_2 = target_seen[target_seen<= 4], target_seen[target_seen> 4]\n",
    "index_1 = target_1.index\n",
    "index_2 = target_2.index\n",
    "features_1, features_2 = features_seen.loc[index_1], features_seen.loc[index_2]\n",
    "print(features_1.shape)\n",
    "print(features_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_1_test, target_1_test_predict,table_gbr_1, feat_scores_gbr_1, model_1 = gbr_model(features_1,target_1, 100000, 1112, 'target_1')\n",
    "#reg_plot(target_1,target_1_test, target_1_test_predict, target_1_predict,'target_1')\n",
    "\n",
    "target_2_test, target_2_test_predict, table_gbr_2, feat_scores_gbr_2, model_2 = gbr_model(features_2,target_2, 100000, 1112, 'target_2')\n",
    "#reg_plot(target_2,target_2_test, target_2_test_predict, target_2_predict,'target_2')\n",
    "\n",
    "pd.concat([table_gbr_1, table_gbr_2], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unseen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_unseen_predict_forest = forest_model.predict(features_unseen)\n",
    "target_unseen_copy = target_unseen.copy()\n",
    "target_unseen_copy[target_unseen <= 4] = 1\n",
    "target_unseen_copy[target_unseen > 4] = 2\n",
    "### plot category of distrbutions based on RandomForestClassifier_model \n",
    "cm = confusion_matrix(target_unseen_copy, target_unseen_predict_forest)\n",
    "fig, ax = plt.subplots(figsize=(3, 3))\n",
    "ax.imshow(cm)\n",
    "ax.grid(False)\n",
    "ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "plt.sca(ax)\n",
    "plt.title('Predict Unseen Data')\n",
    "    \n",
    "print(cm.sum(axis=0)[0])\n",
    "for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax.text(j, i, ('{}').format(int(cm[i, j])), ha='center', va='center', color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seprate unseen data two distributions without forest model\n",
    "index1 = target_unseen[target_unseen_copy == 1].index\n",
    "index2 = target_unseen[target_unseen_copy == 2].index\n",
    "print( set(index1).issubset(features_unseen.index))\n",
    "features_unseen_1 = features_unseen.loc[index1]\n",
    "features_unseen_2 = features_unseen.loc[index2]\n",
    "target_unseen_1 = target_unseen[index1]\n",
    "target_unseen_2 = target_unseen[index2]\n",
    "print('mean(target_unseen_1)', np.mean(target_unseen_1), 'mean(target_unseen_2)', np.mean(target_unseen_2))\n",
    "#----------------------------------------------------------------\n",
    "#predict distribution of data by useing forest model\n",
    "index1 = target_unseen[target_unseen_predict_forest == 1].index\n",
    "index2 = target_unseen[target_unseen_predict_forest == 2].index\n",
    "features_unseen_predict_forest_1 = features_unseen.loc[index1]\n",
    "features_unseen_predict_forest_2 = features_unseen.loc[index2]\n",
    "target_unseen_predict_forest_1 = target_unseen[index1]\n",
    "target_unseen_predict_forest_2 = target_unseen[index2]\n",
    "print('mean(target_unseen_predict_forest_1)', np.mean(target_unseen_predict_forest_1), 'mean(target_unseen_predict_forest_2)', np.mean(target_unseen_predict_forest_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make model to predict TAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_models_with_unseen_data(model, name_target, y, x):\n",
    "    \n",
    "    y_predict = model.predict(x)\n",
    "    data_frame = pd.DataFrame([[name_target, 'Gradient Boosting Regressor', np.sqrt(sum((y - y_predict)**2)/len(y)),\n",
    "                              np.sqrt(sum((y - np.mean(y))**2)/len(y)),\n",
    "                              np.mean(y), np.mean(y_predict)]], \n",
    "                              columns = ['name_target','model','RMS_predict','RMS_target_mean',\n",
    "                                        'mean_target','mean_target_predict'])\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_1 = check_models_with_unseen_data(model_1, \"unseen_1\", target_unseen_1, features_unseen_1)\n",
    "table_1_p = check_models_with_unseen_data(model_1, \"unseen_forest_predicted_1\", target_unseen_predict_forest_1, features_unseen_predict_forest_1)\n",
    "table_2 = check_models_with_unseen_data(model_2, \"unseen_2\", target_unseen_2, features_unseen_2)\n",
    "table_2_p = check_models_with_unseen_data(model_2, \"unseen_forest_predicted_2\", target_unseen_predict_forest_2, features_unseen_predict_forest_2)\n",
    "\n",
    "pd.concat([table_1, table_1_p, table_2, table_2_p], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_unseen_1_predict = model_1.predict(features_unseen_1)\n",
    "target_unseen_2_predict = model_2.predict(features_unseen_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_target_unseen_predict = (sum(target_unseen_1_predict)+sum(target_unseen_2_predict))/(len(target_unseen))\n",
    "mean_target_unseen = np.mean(target_unseen)\n",
    "#print(\"mean_target_unseen_predict:\", mean_target_unseen_predict)\n",
    "#print(\"mean_target_unseen\",mean_target_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSE real data\n",
    "RMSE_targer = np.sqrt(sum((target_unseen - mean_target_unseen)**2))/len(target_unseen)\n",
    "#print(\"RMSE_targer:\", RMSE_targer)\n",
    "sum_1 = sum((target_unseen_1_predict - target_unseen_1)**2)\n",
    "sum_2 = sum((target_unseen_2_predict - target_unseen_2)**2)\n",
    "RMSE_targer_predict = np.sqrt(sum_1+sum_2)/len(target_unseen)\n",
    "#print(\"RMSE_targer_predict:\", RMSE_targer_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
